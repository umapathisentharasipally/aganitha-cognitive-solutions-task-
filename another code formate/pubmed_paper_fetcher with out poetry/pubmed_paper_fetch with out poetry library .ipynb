{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f65cab24",
   "metadata": {},
   "source": [
    "# problem statement \n",
    "- **Your task is to write a Python program to fetch research papers based on a user-specified query. The\n",
    "  program must identify papers with at least one author affiliated with a pharmaceutical or biotech\n",
    "  company and return the results as a CSV file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ba698d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import csv\n",
    "import requests\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "from typing import List, Dict\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cccd598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "PUBMED_API_URL = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
    "PUBMED_FETCH_URL = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0eb64bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_paper_ids(query: str, retmax: int = 300) -> List[str]:\n",
    "    \"\"\"\n",
    "    Fetch paper IDs from PubMed based on the query.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'term': query,\n",
    "        'retmax': retmax,  # Number of results to fetch\n",
    "        'retmode': 'json'\n",
    "    }\n",
    "    response = requests.get(PUBMED_API_URL, params=params)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    return data.get('esearchresult', {}).get('idlist', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "840ab109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_paper_details(paper_ids: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Fetch paper details using IDs.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'id': ','.join(paper_ids),\n",
    "        'retmode': 'xml'\n",
    "    }\n",
    "    response = requests.get(PUBMED_FETCH_URL, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.text  # XML response to be parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "623acf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relevant_info(xml_response: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Parse XML response to extract required fields for each article.\n",
    "    \"\"\"\n",
    "    root = ET.fromstring(xml_response)\n",
    "    articles = []\n",
    "\n",
    "    for article in root.findall('.//PubmedArticle'):\n",
    "        pubmed_id = article.findtext('.//PMID')\n",
    "        title = article.findtext('.//ArticleTitle')\n",
    "        \n",
    "        # Extract publication date\n",
    "        pub_date = article.find('.//PubDate')\n",
    "        if pub_date is not None:\n",
    "            year = pub_date.findtext('Year')\n",
    "            month = pub_date.findtext('Month')\n",
    "            day = pub_date.findtext('Day')\n",
    "            publication_date = f\"{year or ''}-{month or ''}-{day or ''}\".strip('-')\n",
    "        else:\n",
    "            publication_date = None\n",
    "        \n",
    "        # Extract authors and affiliations\n",
    "        authors = article.findall('.//Author')\n",
    "        non_academic_authors = []\n",
    "        company_affiliations = []\n",
    "        corresponding_author_email = None\n",
    "\n",
    "        for author in authors:\n",
    "            affiliation = author.findtext('.//AffiliationInfo/Affiliation')\n",
    "            if affiliation and ('university' not in affiliation.lower() and 'college' not in affiliation.lower()):\n",
    "                last_name = author.findtext('LastName')\n",
    "                first_name = author.findtext('ForeName')\n",
    "                full_name = f\"{first_name or ''} {last_name or ''}\".strip()\n",
    "                if full_name:\n",
    "                    non_academic_authors.append(full_name)\n",
    "                company_affiliations.append(affiliation)\n",
    "                # Extract email using regex\n",
    "                email_match = re.search(r'[\\w\\.-]+@[\\w\\.-]+', affiliation)\n",
    "                if email_match:\n",
    "                    corresponding_author_email = email_match.group(0)\n",
    "\n",
    "        articles.append({\n",
    "            'PubmedID': pubmed_id,\n",
    "            'Title': title,\n",
    "            'Publication Date': publication_date,\n",
    "            'Non-academic Author(s)': ', '.join(non_academic_authors),\n",
    "            'Company Affiliation(s)': ', '.join(company_affiliations),\n",
    "            'Corresponding Author Email': corresponding_author_email\n",
    "        })\n",
    "\n",
    "    return articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a2ca280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(data: List[Dict], filename: str):\n",
    "    \"\"\"\n",
    "    Save extracted data to CSV file.\n",
    "    \"\"\"\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\n",
    "            'PubmedID', 'Title', 'Publication Date', 'Non-academic Author(s)',\n",
    "            'Company Affiliation(s)', 'Corresponding Author Email'\n",
    "        ])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4faef4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: cancer therapy\n",
      "Fetched IDs: ['39789673', '39789641', '39789640', '39789615', '39789613', '39789606', '39789599', '39789555', '39789554', '39789474', '39789471', '39789445', '39789407', '39789372', '39789356', '39789336', '39789298', '39789280', '39789258', '39789257', '39789247', '39789208', '39789190', '39789183', '39789150', '39789071', '39789066', '39789065', '39789010', '39788975', '39788967', '39788945', '39788939', '39788918', '39788912', '39788889', '39788886', '39788877', '39788823', '39788816', '39788744', '39788650', '39788584', '39788569', '39788567', '39788558', '39788520', '39788504', '39788501', '39788500', '39788496', '39788485', '39788431', '39788429', '39788400', '39788396', '39788388', '39788373', '39788354', '39788274', '39788152', '39788148', '39788133', '39788061', '39787980', '39787941', '39787915', '39787807', '39787793', '39787708', '39787688', '39787636', '39787595', '39787561', '39787462', '39787453', '39787447', '39787436', '39787419', '39787392', '39787250', '39787217', '39787212', '39787190', '39787181', '39787178', '39787149', '39787141', '39787077', '39787064', '39787021', '39787015', '39786986', '39786928', '39786764', '39786725', '39786676', '39786672', '39786650', '39786597', '39786586', '39786540', '39786519', '39786518', '39786504', '39786493', '39786465', '39786457', '39786430', '39786420', '39786418', '39786401', '39786391', '39786390', '39785866', '39785827', '39785769', '39785511', '39785419', '39785181', '39785081', '39784999', '39784514', '39784146', '39784117', '39783918', '39783859', '39783856', '39783855', '39783849', '39783838', '39783790', '39783747', '39783647', '39782745', '39782735', '39782693', '39782689', '39782686', '39782564', '39782541', '39782516', '39782515', '39782501', '39782456', '39782258', '39782221', '39781954', '39781751', '39781734', '39781731', '39781729', '39781724', '39781718', '39781716', '39781604', '39781586', '39781576', '39781572', '39781570', '39781520', '39781469', '39781466', '39781459', '39781457', '39781447', '39781381', '39781376', '39781363', '39781350', '39781349', '39781346', '39781342', '39781339', '39781240', '39781239', '39781200', '39781199', '39781192', '39781173', '39781040', '39781038', '39781016', '39780997', '39780958', '39780923', '39780816', '39780756', '39780692', '39780686', '39780649', '39780572', '39780544', '39780531', '39780503', '39780444', '39780402', '39780367', '39780366', '39780302', '39780291', '39780285', '39780280', '39780278', '39780269', '39780248', '39780232', '39780231', '39780187', '39780157', '39780146', '39780142', '39780133', '39780129', '39780119', '39780104', '39780102', '39780099', '39780089', '39780067', '39780053', '39780051', '39780006', '39779996', '39779964', '39779950', '39779930', '39779851', '39779812', '39779797', '39779772', '39779746', '39779693', '39779686', '39779664', '39779635', '39779619', '39779616', '39779611', '39779600', '39779574', '39779573', '39779571', '39779562', '39779554', '39779552', '39779549', '39779537', '39779534', '39779496', '39779492', '39779447', '39779416', '39779412', '39779354', '39779351', '39779280', '39779263', '39779253', '39779210', '39779194', '39779174', '39779170', '39779169', '39779030', '39779027', '39778993', '39778963', '39778860', '39778859', '39778829', '39778743', '39778710', '39778682', '39778658', '39778655', '39778630', '39778525', '39778511', '39778508', '39778326', '39778272', '39778271', '39778243', '39778224', '39778223', '39778222', '39778168', '39778122', '39778113', '39778102', '39778094', '39778090', '39778077', '39778066', '39778029', '39777993', '39777927', '39777919', '39777843']\n",
      "Results saved to output.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    # Simulate command-line arguments for Jupyter Notebook\n",
    "    sys.argv = ['script_name', 'cancer therapy', '-f', 'output.csv', '-d']  # Example arguments\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Fetch PubMed Papers\")\n",
    "    parser.add_argument('query', type=str, help='Search query for PubMed')\n",
    "    parser.add_argument('-f', '--file', type=str, help='Output CSV file')\n",
    "    parser.add_argument('-d', '--debug', action='store_true', help='Enable debug mode')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.debug:\n",
    "        print(f\"Query: {args.query}\")\n",
    "\n",
    "    try:\n",
    "        paper_ids = fetch_paper_ids(args.query)\n",
    "        if args.debug:\n",
    "            print(f\"Fetched IDs: {paper_ids}\")\n",
    "\n",
    "        xml_response = fetch_paper_details(paper_ids)\n",
    "        data = extract_relevant_info(xml_response)\n",
    "\n",
    "        if args.file:\n",
    "            save_to_csv(data, args.file)\n",
    "            print(f\"Results saved to {args.file}\")\n",
    "        else:\n",
    "            print(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3fd52b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
